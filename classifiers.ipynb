{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os,random    \n",
    "def file_name(file_dir):   \n",
    "    L=[]   \n",
    "    for root, dirs, files in os.walk(file_dir):  \n",
    "        for file in files:  \n",
    "            if os.path.splitext(file)[1] == '.txt':  \n",
    "                L.append(os.path.join(root, file))  \n",
    "    return L  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all=range(0,25000)\n",
    "file_pos=file_name(\"A:/dataset/all/pos/\")\n",
    "file_neg=file_name(\"A:/dataset/all/neg/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos=random.sample(all,17500)\n",
    "train_neg=random.sample(all,17500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pos=[x for x in all if x not in train_pos]\n",
    "test_neg=[x for x in all if x not in train_neg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_train_pos=[]\n",
    "docs_train_neg=[]\n",
    "docs_test_pos=[]\n",
    "docs_test_neg=[]\n",
    "\n",
    "for i in range(0,17500):\n",
    "    try:\n",
    "        f = open(file_pos[train_pos[i]], 'r',encoding=\"utf-8\")\n",
    "        docs_train_pos.append(f.read())\n",
    "    finally:\n",
    "        if f:\n",
    "            f.close()\n",
    "\n",
    "for i in range(0,7500):\n",
    "    try:\n",
    "        f = open(file_pos[test_pos[i]], 'r', encoding=\"utf-8\")\n",
    "        docs_test_pos.append(f.read())\n",
    "    finally:\n",
    "        if f:\n",
    "            f.close()\n",
    "            \n",
    "for i in range(0,17500):\n",
    "    try:\n",
    "        f = open(file_neg[train_neg[i]], 'r',encoding=\"utf-8\")\n",
    "        docs_train_neg.append(f.read())\n",
    "    finally:\n",
    "        if f:\n",
    "            f.close()\n",
    "\n",
    "for i in range(0,7500):\n",
    "    try:\n",
    "        f = open(file_neg[test_neg[i]], 'r', encoding=\"utf-8\")\n",
    "        docs_test_neg.append(f.read())\n",
    "    finally:\n",
    "        if f:\n",
    "            f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_train_pos = list(1 ** x for x in range(1,17501))\n",
    "label_train_neg = list(0 * x for x in range(1,17501))\n",
    "label_test_pos = list(1 ** x for x in range(1,7501))\n",
    "label_test_neg = list(0 * x for x in range(1,7501))\n",
    "\n",
    "docs_train = docs_train_pos + docs_train_neg\n",
    "docs_test = docs_test_pos + docs_test_neg\n",
    "\n",
    "label_train = label_train_pos + label_train_neg\n",
    "label_test = label_test_pos + label_test_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "50000\n",
      "35000 15000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "docs = []\n",
    "labels = []\n",
    "\n",
    "docs = docs_train + docs_test\n",
    "labels = label_train +label_test\n",
    "\n",
    "print(len(docs))\n",
    "print(len(labels))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(docs, labels, test_size=0.3)\n",
    "print (len(X_train), len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vec', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)), ('nb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# CountVectorizer, unigram, MultinomialNB\n",
    "clf = Pipeline([\n",
    "('vec', CountVectorizer()),\n",
    "('nb', MultinomialNB())\n",
    "])\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC : 0.8494\n",
      "Precision: 0.8743\n",
      "Recall : 0.8166\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"AUC : {:.4f}\".format(roc_auc_score(y_test, y_pred)))\n",
    "print(\"Precision: {:.4f}\".format(precision_score(y_test, y_pred)))\n",
    "print(\"Recall : {:.4f}\".format(recall_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vec', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       " ...True,\n",
       "        vocabulary=None)), ('nb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# TfidfVectorizer, unigram, MultinomialNB\n",
    "clf = Pipeline([\n",
    "('vec', TfidfVectorizer()),\n",
    "('nb', MultinomialNB())\n",
    "])\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC : 0.8630\n",
      "Precision: 0.8864\n",
      "Recall : 0.8331\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"AUC : {:.4f}\".format(roc_auc_score(y_test, y_pred)))\n",
    "print(\"Precision: {:.4f}\".format(precision_score(y_test, y_pred)))\n",
    "print(\"Recall : {:.4f}\".format(recall_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kingy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vec', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_...penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#CountVectorizer, unigram, LogisticRegression\n",
    "clf = Pipeline([\n",
    "('vec', CountVectorizer()),\n",
    "('lr', LogisticRegression())\n",
    "])\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC : 0.8874\n",
      "Precision: 0.8814\n",
      "Recall : 0.8958\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"AUC : {:.4f}\".format(roc_auc_score(y_test, y_pred)))\n",
    "print(\"Precision: {:.4f}\".format(precision_score(y_test, y_pred)))\n",
    "print(\"Recall : {:.4f}\".format(recall_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kingy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vec', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       " ...penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#TfidfVectorizer, unigram, LogisticRegression\n",
    "clf = Pipeline([\n",
    "('vec', TfidfVectorizer()),\n",
    "('lr', LogisticRegression())\n",
    "])\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC : 0.8974\n",
      "Precision: 0.8878\n",
      "Recall : 0.9102\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"AUC : {:.4f}\".format(roc_auc_score(y_test, y_pred)))\n",
    "print(\"Precision: {:.4f}\".format(precision_score(y_test, y_pred)))\n",
    "print(\"Recall : {:.4f}\".format(recall_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vec', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)), ('nb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#CountVectorizer, bigram, MultinomialNB\n",
    "clf = Pipeline([\n",
    "('vec', CountVectorizer(ngram_range=(1, 2))),\n",
    "('nb', MultinomialNB())\n",
    "])\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC : 0.8814\n",
      "Precision: 0.8986\n",
      "Recall : 0.8601\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"AUC : {:.4f}\".format(roc_auc_score(y_test, y_pred)))\n",
    "print(\"Precision: {:.4f}\".format(precision_score(y_test, y_pred)))\n",
    "print(\"Recall : {:.4f}\".format(recall_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vec', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
       " ...True,\n",
       "        vocabulary=None)), ('nb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#TfidfVectorizer, bigram, MultinomialNB\n",
    "clf = Pipeline([\n",
    "('vec', TfidfVectorizer(ngram_range=(1, 2))),\n",
    "('nb', MultinomialNB())\n",
    "])\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC : 0.8879\n",
      "Precision: 0.9137\n",
      "Recall : 0.8569\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"AUC : {:.4f}\".format(roc_auc_score(y_test, y_pred)))\n",
    "print(\"Precision: {:.4f}\".format(precision_score(y_test, y_pred)))\n",
    "print(\"Recall : {:.4f}\".format(recall_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kingy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vec', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
       "        strip_...penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#CountVectorizer, bigram, LogisticRegression\n",
    "clf = Pipeline([\n",
    "('vec', CountVectorizer(ngram_range=(1, 2))),\n",
    "('lr', LogisticRegression())\n",
    "])\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC : 0.9070\n",
      "Precision: 0.9023\n",
      "Recall : 0.9132\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"AUC : {:.4f}\".format(roc_auc_score(y_test, y_pred)))\n",
    "print(\"Precision: {:.4f}\".format(precision_score(y_test, y_pred)))\n",
    "print(\"Recall : {:.4f}\".format(recall_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kingy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vec', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
       " ...penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#TfidfVectorizer, bigram, LogisticRegression\n",
    "clf = Pipeline([\n",
    "('vec', TfidfVectorizer(ngram_range=(1, 2))),\n",
    "('lr', LogisticRegression())\n",
    "])\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC : 0.8996\n",
      "Precision: 0.8896\n",
      "Recall : 0.9130\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"AUC : {:.4f}\".format(roc_auc_score(y_test, y_pred)))\n",
    "print(\"Precision: {:.4f}\".format(precision_score(y_test, y_pred)))\n",
    "print(\"Recall : {:.4f}\".format(recall_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare data for fasttext\n",
    "for i in range(len(X_train)):\n",
    "    f=open(r\"A:\\train.txt\", \"a+\", encoding='utf-8') \n",
    "    f.writelines(\"__label__\" + str(y_train[i]) + \" \" + X_train[i] + \"\\n\") \n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastText import train_supervised # import the supervised training function\n",
    "model = train_supervised(r\"A:/train.txt\")\n",
    "model.save_model(r\"model.bin\") # save model to a file named \"model.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastText import load_model\n",
    "# load a trained model named \"model.bin\"\n",
    "model = load_model(r\"model.bin\")\n",
    "\n",
    "labels, scores = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for label in labels:\n",
    "    if label[0] == '__label__1':\n",
    "        y_pred.append(1)\n",
    "    else:\n",
    "        y_pred.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC : 0.8749\n",
      "Precision: 0.8632\n",
      "Recall : 0.8917\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score\n",
    "\n",
    "print(\"AUC : {:.4f}\".format(roc_auc_score(y_test, y_pred)))\n",
    "print(\"Precision: {:.4f}\".format(precision_score(y_test, y_pred)))\n",
    "print(\"Recall : {:.4f}\".format(recall_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\kingy\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['model.pkl']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#CountVectorizer, bigram, LogisticRegression has the highest score\n",
    "clf = Pipeline([\n",
    "('vec', CountVectorizer(ngram_range=(1, 2))),\n",
    "('lr', LogisticRegression())\n",
    "])\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "joblib.dump(clf, \"model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
